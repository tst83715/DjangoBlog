# -*- coding: utf-8 -*-
"""ppt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H3oPi84MRjDn_Df0SzgXpfTQ5f126gNn

### 1. 安裝相關套件
"""

import requests
from bs4 import BeautifulSoup

!pip install requests

"""### 2. 定義參數"""

# https://www.ptt.cc/bbs/Stock/index.html
# https://www.ptt.cc/bbs/Lifeismoney/index.html
# https://www.ptt.cc/bbs/Lifeismoney/index4004.html
# https://www.ptt.cc/bbs/Lifeismoney/index4003.html

base_url = "https://www.ptt.cc/bbs/"
target_page_name = "index"
target_page_ext = ".html"

target_board = "Stock"
target_page_num = "4003"


target_url = "{}{}/{}{}{}".format(
      base_url,
      target_board,
      target_page_name,
      target_page_num,
      target_page_ext,
    )
target_url

"""### 透過 Requests 取得資料"""

res = requests.get(target_url)
res.text

"""### 透過 BeautifulSoup 解析程式碼"""

html = BeautifulSoup(res.text)

"""### 3. 從 Class 找出資料目標"""

article_title = html.find_all('div', class_='title')
print(type(article_title))
print(article_title[0])

article_link_div = article_title[0]
a_tag = article_link_div.find('a')
link_url = a_tag.attrs['href']
link_content = a_tag.contents

print("<a> 標籤的 attrs: href:", link_url)
print("<a> 標籤的文字內容:", link_content[0])

"""### HTML Tag 組成

```
<標籤 屬性1="值1" 屬性2="值2">
    內容
</標籤>
```
"""

article_title = html.find_all('div', class_='title')

for title in article_title:
  temp_url = title.find('a').attrs['href']
  temp_title = title.find('a').contents[0]
  print(temp_url, temp_title)

# 目標網址下載程式碼
article_url = "https://www.ptt.cc" + "/bbs/Stock/M.1629865915.A.A54.html"
article_html = requests.get(article_url)
article_html = BeautifulSoup(article_html.text)

# 文章內容
content = article_html.find('div', id='main-content').text

# 時間字串
article_time = article_html.find('div', id='main-content').find_all('div', class_='article-metaline')[2].find_all('span')[1].contents[0]



# 用時間分割字串
content = content.split(article_time)[1]

#用字串找出結束
content_end_string = u'※ 發信站:'
content = content.split(content_end_string)[0]

# print(content)

# 找作者
author = article_html.find('div', id='main-content').find_all('div', class_='article-metaline')[0].find_all('span')[1].contents[0].split(" ")[0]
author

"""### 4. 合併為迴圈讀取文章"""

import time
import pandas
full_article = []

target_url = "https://www.ptt.cc/bbs/Stock/index9017.html"
res = requests.get(target_url)
html = BeautifulSoup(res.text)

article_title = html.find_all('div', class_='title')

for title in article_title:
  try:
    temp_url = title.find('a').attrs['href']
    temp_title = title.find('a').contents[0]

    article_url = "https://www.ptt.cc" + temp_url
    article_html = requests.get(article_url)
    article_html = BeautifulSoup(article_html.text)

    # 文章內容
    content = article_html.find('div', id='main-content').text

    # 時間字串
    article_time = article_html.find('div', id='main-content').find_all('div', class_='article-metaline')[2].find_all('span')[1].contents[0]

    # 用時間分割字串
    content = content.split(article_time)[1]

    #用字串找出結束
    content_end_string = u'※ 發信站:'
    content = content.split(content_end_string)[0]

    # 找作者
    author = article_html.find('div', id='main-content').find_all('div', class_='article-metaline')[0].find_all('span')[1].contents[0].split(" ")[0]

  except:
    temp_title = "(本文已被刪除)"
    author = "無"
    content = "無"
    article_time = None

  temp_dict = {
      'url': temp_url,
      'title':  temp_title,
      'content': content,
      'author': author,
      'time': article_time
  }

  full_article.append(temp_dict)
  time.sleep(0.5)

import pandas
full_article_pd = pandas.DataFrame(full_article)
full_article_pd

from google.colab import drive
drive.mount('/content/gdrive')
full_article_pd.to_json('/content/gdrive/My Drive/10-Colab Notebooks/ptt.json')